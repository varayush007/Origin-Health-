{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9nGirfMLohBq"
      },
      "source": [
        "Mounting Colab with Drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niPscyxoolMD",
        "outputId": "2764502d-6c3a-49f3-9a30-5922c307276a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MoTktgmYovIV"
      },
      "source": [
        "Loading necessary libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "fVfGBZPUXRBb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from PIL import Image\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader, random_split\n",
        "import torchvision.transforms as transforms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0TLQqzMon2m"
      },
      "source": [
        "Preparing  the Dataset with Masks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "DJSMk4FmXash"
      },
      "outputs": [],
      "source": [
        "class SegmentationDataset(Dataset):\n",
        "    def __init__(self, image_dir, mask_dir, transform=None):\n",
        "        self.image_dir = image_dir\n",
        "        self.mask_dir = mask_dir\n",
        "        self.transform = transform\n",
        "        self.image_files = os.listdir(image_dir)\n",
        "        self.mask_files = os.listdir(mask_dir)\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_name = os.path.join(self.image_dir, self.image_files[idx])\n",
        "        mask_name = os.path.join(self.mask_dir, self.mask_files[idx])\n",
        "\n",
        "        image = Image.open(img_name).convert(\"RGB\")\n",
        "        mask = Image.open(mask_name).convert(\"L\")  # Ensure masks are grayscale\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "            mask = self.transform(mask)\n",
        "\n",
        "        return {'image': image, 'mask': mask}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gsIAXB7Oo0o0"
      },
      "source": [
        "Transforming the Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "hGyWfNR1XcJ6"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.Resize((256, 256)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JdY19sBco5aD"
      },
      "source": [
        "Specifying image and mask directories"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "PCkuEMEBXdvH"
      },
      "outputs": [],
      "source": [
        "image_dir = '/content/drive/MyDrive/images'\n",
        "mask_dir = '/content/drive/MyDrive/masks'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "885CcJsho7UQ"
      },
      "source": [
        "Creating instance of SegmentationDataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "WFYtjfoXXhha"
      },
      "outputs": [],
      "source": [
        "segmentation_dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UTrSryV5o65f"
      },
      "source": [
        "Segmentation Model Architecture (U-Net)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "Pi63kDLhXml5"
      },
      "outputs": [],
      "source": [
        "# Define the U-Net architecture for segmentation\n",
        "class UNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(UNet, self).__init__()\n",
        "        # Define encoder layers\n",
        "        self.encoder = nn.Sequential(\n",
        "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
        "            nn.Conv2d(64, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(128, 128, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "        )\n",
        "        # Define decoder layers\n",
        "        self.decoder = nn.Sequential(\n",
        "            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.ConvTranspose2d(64, 64, kernel_size=2, stride=2),  # Additional upsampling layer\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Conv2d(64, 1, kernel_size=1)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.encoder(x)\n",
        "        print(\"After encoder:\", x.size())  # Print size after encoder\n",
        "        x = self.decoder(x)\n",
        "        print(\"After decoder:\", x.size())  # Print size after decoder\n",
        "        return x\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "otVLf54KpBjY"
      },
      "source": [
        "Defining loss function and optimizer for segmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "BUCaNrxHXoWx"
      },
      "outputs": [],
      "source": [
        "criterion_seg = nn.BCEWithLogitsLoss()  # Binary Cross-Entropy Loss for segmentation\n",
        "optimizer_seg = torch.optim.Adam(segmentation_model.parameters(), lr=0.001)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXOHdUW-pEhH"
      },
      "source": [
        "Spliting the data in test, val and training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "isr0NBYQXsgv"
      },
      "outputs": [],
      "source": [
        "train_size_seg = int(0.6 * len(segmentation_dataset))\n",
        "val_size_seg = int(0.2 * len(segmentation_dataset))\n",
        "test_size_seg = len(segmentation_dataset) - train_size_seg - val_size_seg\n",
        "\n",
        "train_dataset_seg, val_dataset_seg, test_dataset_seg = random_split(segmentation_dataset,\n",
        "                                                                    [train_size_seg, val_size_seg, test_size_seg])\n",
        "\n",
        "# Defining batch size and create data loaders\n",
        "batch_size_seg = 8\n",
        "train_loader_seg = DataLoader(train_dataset_seg, batch_size=batch_size_seg, shuffle=True)\n",
        "val_loader_seg = DataLoader(val_dataset_seg, batch_size=batch_size_seg, shuffle=False)\n",
        "test_loader_seg = DataLoader(test_dataset_seg, batch_size=batch_size_seg, shuffle=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Aavjd2zpH7T"
      },
      "source": [
        "Training the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kBXdt_XBXwEo",
        "outputId": "0a794482-db60-4320-dc10-38ce4b5d94b5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Epoch [1/10], Training Loss: 0.1350\n",
            "Segmentation Epoch [2/10], Training Loss: 0.0428\n",
            "Segmentation Epoch [3/10], Training Loss: 0.0418\n",
            "Segmentation Epoch [4/10], Training Loss: 0.0412\n",
            "Segmentation Epoch [5/10], Training Loss: 0.0408\n",
            "Segmentation Epoch [6/10], Training Loss: 0.0406\n",
            "Segmentation Epoch [7/10], Training Loss: 0.0405\n",
            "Segmentation Epoch [8/10], Training Loss: 0.0405\n",
            "Segmentation Epoch [9/10], Training Loss: 0.0404\n",
            "Segmentation Epoch [10/10], Training Loss: 0.0404\n"
          ]
        }
      ],
      "source": [
        "num_epochs_seg = 10\n",
        "\n",
        "# Training the segmentation model\n",
        "for epoch in range(num_epochs_seg):\n",
        "    segmentation_model.train()\n",
        "    running_loss_seg = 0.0\n",
        "\n",
        "    for batch_idx, batch_seg in enumerate(train_loader_seg):\n",
        "        images_seg, masks_seg = batch_seg['image'], batch_seg['mask']\n",
        "\n",
        "        optimizer_seg.zero_grad()\n",
        "\n",
        "        outputs_seg = segmentation_model(images_seg)\n",
        "\n",
        "      \n",
        "        masks_seg_resized = nn.functional.interpolate(masks_seg, size=outputs_seg.shape[2:], mode='bilinear', align_corners=True)\n",
        "\n",
        "        loss_seg = criterion_seg(outputs_seg, masks_seg_resized)\n",
        "        loss_seg.backward()\n",
        "        optimizer_seg.step()\n",
        "\n",
        "        running_loss_seg += loss_seg.item() * images_seg.size(0)\n",
        "\n",
        "    epoch_loss_seg = running_loss_seg / len(train_dataset_seg)\n",
        "    print(f'Segmentation Epoch [{epoch + 1}/{num_epochs_seg}], Training Loss: {epoch_loss_seg:.4f}')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fLCCQ6rZpKRr"
      },
      "source": [
        "Evaluating the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ilN_rlyiX4iK",
        "outputId": "2c6001da-efef-4d14-f334-ab9f379716d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Segmentation Test Loss: 0.0414\n"
          ]
        }
      ],
      "source": [
        "# Evaluating the segmentation model on the test set\n",
        "segmentation_model.eval()\n",
        "test_loss_seg = 0.0\n",
        "\n",
        "for batch_idx, batch_seg in enumerate(test_loader_seg):\n",
        "    images_seg, masks_seg = batch_seg['image'], batch_seg['mask']\n",
        "\n",
        "    outputs_seg = segmentation_model(images_seg)\n",
        "    outputs_seg_resized  = nn.functional.interpolate(outputs_seg, size=(256, 256), mode='bilinear', align_corners=False)\n",
        "    loss_seg = criterion_seg(outputs_seg_resized, masks_seg)\n",
        "\n",
        "    test_loss_seg += loss_seg.item() * images_seg.size(0)\n",
        "\n",
        "test_loss_seg /= len(test_dataset_seg)\n",
        "print(f'Segmentation Test Loss: {test_loss_seg:.4f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c0QiC0H9pMgI"
      },
      "source": [
        "Post Processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OpoDDcTpnMbi",
        "outputId": "104f6e45-93f2-4216-f13c-3387d643df53"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[((61.72146224975586, 61.57270050048828), (61.72146224975586, -9.981918334960938)), ((63.56726837158203, 62.992279052734375), (63.56726837158203, -8.581222534179688)), ((64.40462493896484, 64.58597564697266), (64.40462493896484, -7.562721252441406)), ((65.13460540771484, 62.57162857055664), (65.13460540771484, -10.819377899169922)), ((63.77444076538086, 62.554222106933594), (63.77444076538086, -9.828193664550781)), ((64.01751708984375, 63.684635162353516), (64.01751708984375, -7.604160308837891)), ((63.452945709228516, 64.12628173828125), (63.452945709228516, -6.493339538574219)), ((63.53681564331055, 64.16344451904297), (63.53681564331055, -12.480850219726562))]\n"
          ]
        }
      ],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "def post_process_segmentation(output_masks):\n",
        "    biometry_points = []\n",
        "\n",
        "    for mask in output_masks:\n",
        "       \n",
        "        mask_np = mask.squeeze().cpu().numpy()\n",
        "\n",
        "      \n",
        "        contours, _ = cv2.findContours((mask_np * 255).astype(np.uint8), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "\n",
        "       \n",
        "        if contours:\n",
        "            contour = max(contours, key=cv2.contourArea)\n",
        "            ellipse = cv2.fitEllipse(contour)\n",
        "\n",
        "            \n",
        "            center = ellipse[0]\n",
        "            top_point = (center[0], center[1] - ellipse[1][1] / 2)\n",
        "            biometry_points.append((center, top_point))\n",
        "        else:\n",
        "            \n",
        "            biometry_points.append((None, None))\n",
        "\n",
        "    return biometry_points\n",
        "\n",
        "\n",
        "output_masks = [torch.rand(1, 128, 128) > 0.5 for _ in range(8)]  # Example output masks\n",
        "biometry_points = post_process_segmentation(output_masks)\n",
        "print(biometry_points)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
